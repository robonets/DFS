{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "868e5768-68c8-4e3e-9e68-01b08a83f25e",
   "metadata": {},
   "source": [
    "DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea6a7db0-85cc-49c2-b12b-457ba1c24c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator\n",
    "\n",
    "class MyIterator:\n",
    "    def __init__(self, max_cnt):\n",
    "        self.max_cnt = max_cnt\n",
    "        self.cnt = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.cnt == self.max_cnt:\n",
    "            raise StopIteration()\n",
    "        self.cnt += 1\n",
    "        return self.cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f6007bf-0e8f-498f-9eeb-768480fa3531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "obj = MyIterator(5)\n",
    "for x in obj:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6780b446-bbde-4a03-89af-a396d8ef81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.data_size = len(dataset)\n",
    "        self.max_iter = math.ceil(self.data_size / batch_size)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.iteration = 0\n",
    "        if self.shuffle:\n",
    "            self.index = np.random.permutation(len(self.dataset))\n",
    "        else:\n",
    "            self.index = np.arange(len(self.dataset))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.iteration >= self.max_iter:\n",
    "            self.reset()\n",
    "            raise StopIteration\n",
    "\n",
    "        i, batch_size = self.iteration, self.batch_size\n",
    "        batch_index = self.index[i * batch_size:(i + 1) * batch_size]\n",
    "        batch = [self.dataset[i] for i in batch_index]\n",
    "\n",
    "        x = xp.array([example[0] for example in batch])\n",
    "        t = xp.array([example[1] for example in batch])\n",
    "\n",
    "        self.iteration += 1\n",
    "        return x, t\n",
    "\n",
    "    def next(self):\n",
    "        return self.__next__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "713658e7-2c42-45b9-a281-ca999794d7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2) (10,)\n",
      "(10, 2) (10,)\n"
     ]
    }
   ],
   "source": [
    "from dezero.datasets import Spiral\n",
    "from dezero import DataLoader\n",
    "\n",
    "batch_size = 10\n",
    "max_epoch = 1\n",
    "\n",
    "train_set = Spiral(train=True)\n",
    "test_set = Spiral(train=False)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size, shuffle=False)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for x, t in train_loader:\n",
    "        print(x.shape, t.shape)\n",
    "        break\n",
    "\n",
    "    for x, t in test_loader:\n",
    "        print(x.shape, t.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e181640-2d7c-43fc-9e8c-2a0bee1ff7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy function\n",
    "\n",
    "def accuracy(y, t):\n",
    "    \"\"\"\n",
    "    [WAR] This function is not differentiable.\n",
    "    \"\"\"\n",
    "    y, t = as_variable(y), as_variable(t)\n",
    "\n",
    "    pred = y.data.argmax(axis=1).reshape(t.shape)\n",
    "    result = (pred == t.data)\n",
    "    acc = result.mean()\n",
    "    return Variable(as_array(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39ce3806-161b-44a1-b2b2-5f82012d5893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(0.6666666666666666)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dezero.functions as F\n",
    "\n",
    "y = np.array([[0.2, 0.8, 0],[0.1, 0.9, 0], [0.8, 0.1, 0.1]])\n",
    "t = np.array([1,2,0])\n",
    "acc = F.accuracy(y, t)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26ade7b6-8201-4be3-9e2b-1218a76c30ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "train loss: 1.0944, accuracy: 0.4033\n",
      "test loss: 1.0468, accuracy: 0.3267\n",
      "epoch: 2\n",
      "train loss: 0.9882, accuracy: 0.4933\n",
      "test loss: 0.9729, accuracy: 0.4333\n",
      "epoch: 3\n",
      "train loss: 0.9403, accuracy: 0.5133\n",
      "test loss: 0.8965, accuracy: 0.6233\n",
      "epoch: 4\n",
      "train loss: 0.8820, accuracy: 0.5700\n",
      "test loss: 0.8771, accuracy: 0.5967\n",
      "epoch: 5\n",
      "train loss: 0.8617, accuracy: 0.5600\n",
      "test loss: 0.8670, accuracy: 0.5867\n",
      "epoch: 6\n",
      "train loss: 0.8313, accuracy: 0.5300\n",
      "test loss: 0.8654, accuracy: 0.6000\n",
      "epoch: 7\n",
      "train loss: 0.8086, accuracy: 0.5833\n",
      "test loss: 0.7950, accuracy: 0.5600\n",
      "epoch: 8\n",
      "train loss: 0.7948, accuracy: 0.5733\n",
      "test loss: 0.7921, accuracy: 0.5900\n",
      "epoch: 9\n",
      "train loss: 0.7728, accuracy: 0.5500\n",
      "test loss: 0.7718, accuracy: 0.5300\n",
      "epoch: 10\n",
      "train loss: 0.7643, accuracy: 0.5633\n",
      "test loss: 0.7796, accuracy: 0.5800\n",
      "epoch: 11\n",
      "train loss: 0.7862, accuracy: 0.5600\n",
      "test loss: 0.7701, accuracy: 0.5633\n",
      "epoch: 12\n",
      "train loss: 0.7914, accuracy: 0.5500\n",
      "test loss: 0.8218, accuracy: 0.6067\n",
      "epoch: 13\n",
      "train loss: 0.7633, accuracy: 0.5567\n",
      "test loss: 0.7757, accuracy: 0.5800\n",
      "epoch: 14\n",
      "train loss: 0.7612, accuracy: 0.5833\n",
      "test loss: 0.7800, accuracy: 0.5667\n",
      "epoch: 15\n",
      "train loss: 0.7408, accuracy: 0.5667\n",
      "test loss: 0.7654, accuracy: 0.5867\n",
      "epoch: 16\n",
      "train loss: 0.7453, accuracy: 0.5733\n",
      "test loss: 0.7648, accuracy: 0.6033\n",
      "epoch: 17\n",
      "train loss: 0.7843, accuracy: 0.5667\n",
      "test loss: 0.7415, accuracy: 0.5267\n",
      "epoch: 18\n",
      "train loss: 0.7592, accuracy: 0.5633\n",
      "test loss: 0.7388, accuracy: 0.5267\n",
      "epoch: 19\n",
      "train loss: 0.7396, accuracy: 0.5567\n",
      "test loss: 0.7791, accuracy: 0.5667\n",
      "epoch: 20\n",
      "train loss: 0.7376, accuracy: 0.5533\n",
      "test loss: 0.7478, accuracy: 0.5200\n",
      "epoch: 21\n",
      "train loss: 0.7469, accuracy: 0.5600\n",
      "test loss: 0.7617, accuracy: 0.6100\n",
      "epoch: 22\n",
      "train loss: 0.7349, accuracy: 0.5667\n",
      "test loss: 0.7476, accuracy: 0.5967\n",
      "epoch: 23\n",
      "train loss: 0.7650, accuracy: 0.5600\n",
      "test loss: 0.7336, accuracy: 0.5433\n",
      "epoch: 24\n",
      "train loss: 0.7495, accuracy: 0.5667\n",
      "test loss: 0.7366, accuracy: 0.5500\n",
      "epoch: 25\n",
      "train loss: 0.7414, accuracy: 0.5700\n",
      "test loss: 0.7516, accuracy: 0.6133\n",
      "epoch: 26\n",
      "train loss: 0.7298, accuracy: 0.5900\n",
      "test loss: 0.7327, accuracy: 0.5533\n",
      "epoch: 27\n",
      "train loss: 0.7297, accuracy: 0.5700\n",
      "test loss: 0.7356, accuracy: 0.5933\n",
      "epoch: 28\n",
      "train loss: 0.7267, accuracy: 0.5900\n",
      "test loss: 0.7240, accuracy: 0.5233\n",
      "epoch: 29\n",
      "train loss: 0.7359, accuracy: 0.5800\n",
      "test loss: 0.7203, accuracy: 0.5533\n",
      "epoch: 30\n",
      "train loss: 0.7273, accuracy: 0.5600\n",
      "test loss: 0.7382, accuracy: 0.5433\n",
      "epoch: 31\n",
      "train loss: 0.7338, accuracy: 0.5867\n",
      "test loss: 0.7492, accuracy: 0.5933\n",
      "epoch: 32\n",
      "train loss: 0.7092, accuracy: 0.5900\n",
      "test loss: 0.7241, accuracy: 0.5500\n",
      "epoch: 33\n",
      "train loss: 0.6970, accuracy: 0.5767\n",
      "test loss: 0.7483, accuracy: 0.6167\n",
      "epoch: 34\n",
      "train loss: 0.7048, accuracy: 0.5967\n",
      "test loss: 0.7170, accuracy: 0.5433\n",
      "epoch: 35\n",
      "train loss: 0.7069, accuracy: 0.5967\n",
      "test loss: 0.7164, accuracy: 0.5467\n",
      "epoch: 36\n",
      "train loss: 0.7199, accuracy: 0.5800\n",
      "test loss: 0.7318, accuracy: 0.6133\n",
      "epoch: 37\n",
      "train loss: 0.7035, accuracy: 0.6167\n",
      "test loss: 0.7266, accuracy: 0.5900\n",
      "epoch: 38\n",
      "train loss: 0.6992, accuracy: 0.5767\n",
      "test loss: 0.7419, accuracy: 0.6000\n",
      "epoch: 39\n",
      "train loss: 0.7103, accuracy: 0.6000\n",
      "test loss: 0.7077, accuracy: 0.5333\n",
      "epoch: 40\n",
      "train loss: 0.7064, accuracy: 0.5733\n",
      "test loss: 0.7335, accuracy: 0.5900\n",
      "epoch: 41\n",
      "train loss: 0.7022, accuracy: 0.5767\n",
      "test loss: 0.7087, accuracy: 0.6100\n",
      "epoch: 42\n",
      "train loss: 0.7047, accuracy: 0.6000\n",
      "test loss: 0.6951, accuracy: 0.5800\n",
      "epoch: 43\n",
      "train loss: 0.7071, accuracy: 0.6000\n",
      "test loss: 0.7009, accuracy: 0.6133\n",
      "epoch: 44\n",
      "train loss: 0.7041, accuracy: 0.6033\n",
      "test loss: 0.6914, accuracy: 0.5833\n",
      "epoch: 45\n",
      "train loss: 0.6854, accuracy: 0.5767\n",
      "test loss: 0.7122, accuracy: 0.6100\n",
      "epoch: 46\n",
      "train loss: 0.6771, accuracy: 0.6067\n",
      "test loss: 0.6874, accuracy: 0.5600\n",
      "epoch: 47\n",
      "train loss: 0.6781, accuracy: 0.5900\n",
      "test loss: 0.6995, accuracy: 0.6467\n",
      "epoch: 48\n",
      "train loss: 0.6875, accuracy: 0.5933\n",
      "test loss: 0.7021, accuracy: 0.6300\n",
      "epoch: 49\n",
      "train loss: 0.6641, accuracy: 0.6000\n",
      "test loss: 0.6897, accuracy: 0.6000\n",
      "epoch: 50\n",
      "train loss: 0.6683, accuracy: 0.6200\n",
      "test loss: 0.6850, accuracy: 0.5867\n",
      "epoch: 51\n",
      "train loss: 0.6554, accuracy: 0.6033\n",
      "test loss: 0.6698, accuracy: 0.6367\n",
      "epoch: 52\n",
      "train loss: 0.6528, accuracy: 0.6200\n",
      "test loss: 0.6789, accuracy: 0.5800\n",
      "epoch: 53\n",
      "train loss: 0.6500, accuracy: 0.6467\n",
      "test loss: 0.6691, accuracy: 0.6467\n",
      "epoch: 54\n",
      "train loss: 0.6449, accuracy: 0.6267\n",
      "test loss: 0.6562, accuracy: 0.6633\n",
      "epoch: 55\n",
      "train loss: 0.6549, accuracy: 0.6500\n",
      "test loss: 0.6892, accuracy: 0.6467\n",
      "epoch: 56\n",
      "train loss: 0.6504, accuracy: 0.6400\n",
      "test loss: 0.6421, accuracy: 0.6167\n",
      "epoch: 57\n",
      "train loss: 0.6396, accuracy: 0.6667\n",
      "test loss: 0.6451, accuracy: 0.6167\n",
      "epoch: 58\n",
      "train loss: 0.6251, accuracy: 0.6733\n",
      "test loss: 0.6415, accuracy: 0.6200\n",
      "epoch: 59\n",
      "train loss: 0.6150, accuracy: 0.6433\n",
      "test loss: 0.6285, accuracy: 0.6267\n",
      "epoch: 60\n",
      "train loss: 0.6122, accuracy: 0.6633\n",
      "test loss: 0.6169, accuracy: 0.6400\n",
      "epoch: 61\n",
      "train loss: 0.5987, accuracy: 0.6767\n",
      "test loss: 0.6183, accuracy: 0.6167\n",
      "epoch: 62\n",
      "train loss: 0.5920, accuracy: 0.6667\n",
      "test loss: 0.6076, accuracy: 0.6967\n",
      "epoch: 63\n",
      "train loss: 0.5914, accuracy: 0.6700\n",
      "test loss: 0.6020, accuracy: 0.6300\n",
      "epoch: 64\n",
      "train loss: 0.5911, accuracy: 0.6867\n",
      "test loss: 0.5981, accuracy: 0.6533\n",
      "epoch: 65\n",
      "train loss: 0.5626, accuracy: 0.7000\n",
      "test loss: 0.6124, accuracy: 0.7100\n",
      "epoch: 66\n",
      "train loss: 0.5707, accuracy: 0.7067\n",
      "test loss: 0.5760, accuracy: 0.6567\n",
      "epoch: 67\n",
      "train loss: 0.5574, accuracy: 0.6900\n",
      "test loss: 0.5834, accuracy: 0.6967\n",
      "epoch: 68\n",
      "train loss: 0.5560, accuracy: 0.7133\n",
      "test loss: 0.5589, accuracy: 0.6933\n",
      "epoch: 69\n",
      "train loss: 0.5355, accuracy: 0.7267\n",
      "test loss: 0.5530, accuracy: 0.6967\n",
      "epoch: 70\n",
      "train loss: 0.5303, accuracy: 0.7300\n",
      "test loss: 0.5380, accuracy: 0.7267\n",
      "epoch: 71\n",
      "train loss: 0.5207, accuracy: 0.7167\n",
      "test loss: 0.5315, accuracy: 0.7367\n",
      "epoch: 72\n",
      "train loss: 0.5094, accuracy: 0.7533\n",
      "test loss: 0.5340, accuracy: 0.7367\n",
      "epoch: 73\n",
      "train loss: 0.5110, accuracy: 0.7400\n",
      "test loss: 0.5127, accuracy: 0.7433\n",
      "epoch: 74\n",
      "train loss: 0.4921, accuracy: 0.7500\n",
      "test loss: 0.5051, accuracy: 0.7400\n",
      "epoch: 75\n",
      "train loss: 0.4882, accuracy: 0.7700\n",
      "test loss: 0.5268, accuracy: 0.7467\n",
      "epoch: 76\n",
      "train loss: 0.4859, accuracy: 0.7533\n",
      "test loss: 0.4997, accuracy: 0.7400\n",
      "epoch: 77\n",
      "train loss: 0.4701, accuracy: 0.7767\n",
      "test loss: 0.4814, accuracy: 0.7800\n",
      "epoch: 78\n",
      "train loss: 0.4574, accuracy: 0.7733\n",
      "test loss: 0.4736, accuracy: 0.7700\n",
      "epoch: 79\n",
      "train loss: 0.4547, accuracy: 0.7533\n",
      "test loss: 0.4665, accuracy: 0.7900\n",
      "epoch: 80\n",
      "train loss: 0.4533, accuracy: 0.7667\n",
      "test loss: 0.4601, accuracy: 0.7900\n",
      "epoch: 81\n",
      "train loss: 0.4431, accuracy: 0.7967\n",
      "test loss: 0.4496, accuracy: 0.7900\n",
      "epoch: 82\n",
      "train loss: 0.4309, accuracy: 0.8167\n",
      "test loss: 0.4421, accuracy: 0.7867\n",
      "epoch: 83\n",
      "train loss: 0.4282, accuracy: 0.8167\n",
      "test loss: 0.4431, accuracy: 0.7833\n",
      "epoch: 84\n",
      "train loss: 0.4132, accuracy: 0.8167\n",
      "test loss: 0.4353, accuracy: 0.8200\n",
      "epoch: 85\n",
      "train loss: 0.4132, accuracy: 0.8167\n",
      "test loss: 0.4260, accuracy: 0.8367\n",
      "epoch: 86\n",
      "train loss: 0.4047, accuracy: 0.8167\n",
      "test loss: 0.4248, accuracy: 0.8400\n",
      "epoch: 87\n",
      "train loss: 0.3968, accuracy: 0.8367\n",
      "test loss: 0.4031, accuracy: 0.8333\n",
      "epoch: 88\n",
      "train loss: 0.3942, accuracy: 0.8267\n",
      "test loss: 0.4091, accuracy: 0.8333\n",
      "epoch: 89\n",
      "train loss: 0.3746, accuracy: 0.8333\n",
      "test loss: 0.3962, accuracy: 0.8100\n",
      "epoch: 90\n",
      "train loss: 0.3772, accuracy: 0.8333\n",
      "test loss: 0.3831, accuracy: 0.8300\n",
      "epoch: 91\n",
      "train loss: 0.3669, accuracy: 0.8467\n",
      "test loss: 0.3844, accuracy: 0.8433\n",
      "epoch: 92\n",
      "train loss: 0.3554, accuracy: 0.8600\n",
      "test loss: 0.3752, accuracy: 0.8567\n",
      "epoch: 93\n",
      "train loss: 0.3491, accuracy: 0.8700\n",
      "test loss: 0.3720, accuracy: 0.8400\n",
      "epoch: 94\n",
      "train loss: 0.3440, accuracy: 0.8533\n",
      "test loss: 0.3595, accuracy: 0.8600\n",
      "epoch: 95\n",
      "train loss: 0.3408, accuracy: 0.8633\n",
      "test loss: 0.3533, accuracy: 0.8700\n",
      "epoch: 96\n",
      "train loss: 0.3336, accuracy: 0.8600\n",
      "test loss: 0.3515, accuracy: 0.8800\n",
      "epoch: 97\n",
      "train loss: 0.3295, accuracy: 0.8700\n",
      "test loss: 0.3437, accuracy: 0.8933\n",
      "epoch: 98\n",
      "train loss: 0.3208, accuracy: 0.9133\n",
      "test loss: 0.3433, accuracy: 0.8533\n",
      "epoch: 99\n",
      "train loss: 0.3212, accuracy: 0.8667\n",
      "test loss: 0.3302, accuracy: 0.8633\n",
      "epoch: 100\n",
      "train loss: 0.3146, accuracy: 0.8700\n",
      "test loss: 0.3248, accuracy: 0.8600\n",
      "epoch: 101\n",
      "train loss: 0.3090, accuracy: 0.8633\n",
      "test loss: 0.3268, accuracy: 0.8833\n",
      "epoch: 102\n",
      "train loss: 0.3024, accuracy: 0.8933\n",
      "test loss: 0.3195, accuracy: 0.8533\n",
      "epoch: 103\n",
      "train loss: 0.3009, accuracy: 0.8933\n",
      "test loss: 0.3122, accuracy: 0.8900\n",
      "epoch: 104\n",
      "train loss: 0.2930, accuracy: 0.9067\n",
      "test loss: 0.3087, accuracy: 0.8633\n",
      "epoch: 105\n",
      "train loss: 0.2881, accuracy: 0.9067\n",
      "test loss: 0.3111, accuracy: 0.8567\n",
      "epoch: 106\n",
      "train loss: 0.2785, accuracy: 0.9167\n",
      "test loss: 0.3026, accuracy: 0.8867\n",
      "epoch: 107\n",
      "train loss: 0.2786, accuracy: 0.8933\n",
      "test loss: 0.2952, accuracy: 0.8833\n",
      "epoch: 108\n",
      "train loss: 0.2756, accuracy: 0.9100\n",
      "test loss: 0.2912, accuracy: 0.8800\n",
      "epoch: 109\n",
      "train loss: 0.2744, accuracy: 0.9200\n",
      "test loss: 0.2965, accuracy: 0.8667\n",
      "epoch: 110\n",
      "train loss: 0.2705, accuracy: 0.9267\n",
      "test loss: 0.2856, accuracy: 0.8933\n",
      "epoch: 111\n",
      "train loss: 0.2645, accuracy: 0.9067\n",
      "test loss: 0.2814, accuracy: 0.8867\n",
      "epoch: 112\n",
      "train loss: 0.2624, accuracy: 0.9100\n",
      "test loss: 0.2835, accuracy: 0.8700\n",
      "epoch: 113\n",
      "train loss: 0.2608, accuracy: 0.9067\n",
      "test loss: 0.2752, accuracy: 0.8933\n",
      "epoch: 114\n",
      "train loss: 0.2524, accuracy: 0.9167\n",
      "test loss: 0.2740, accuracy: 0.9033\n",
      "epoch: 115\n",
      "train loss: 0.2484, accuracy: 0.9167\n",
      "test loss: 0.2688, accuracy: 0.8967\n",
      "epoch: 116\n",
      "train loss: 0.2480, accuracy: 0.9200\n",
      "test loss: 0.2768, accuracy: 0.8600\n",
      "epoch: 117\n",
      "train loss: 0.2445, accuracy: 0.9133\n",
      "test loss: 0.2635, accuracy: 0.9067\n",
      "epoch: 118\n",
      "train loss: 0.2444, accuracy: 0.9267\n",
      "test loss: 0.2593, accuracy: 0.8967\n",
      "epoch: 119\n",
      "train loss: 0.2379, accuracy: 0.9267\n",
      "test loss: 0.2576, accuracy: 0.8867\n",
      "epoch: 120\n",
      "train loss: 0.2361, accuracy: 0.9200\n",
      "test loss: 0.2573, accuracy: 0.9200\n",
      "epoch: 121\n",
      "train loss: 0.2372, accuracy: 0.9333\n",
      "test loss: 0.2534, accuracy: 0.9067\n",
      "epoch: 122\n",
      "train loss: 0.2305, accuracy: 0.9333\n",
      "test loss: 0.2511, accuracy: 0.8867\n",
      "epoch: 123\n",
      "train loss: 0.2277, accuracy: 0.9367\n",
      "test loss: 0.2531, accuracy: 0.9000\n",
      "epoch: 124\n",
      "train loss: 0.2318, accuracy: 0.9233\n",
      "test loss: 0.2456, accuracy: 0.9067\n",
      "epoch: 125\n",
      "train loss: 0.2248, accuracy: 0.9400\n",
      "test loss: 0.2454, accuracy: 0.9133\n",
      "epoch: 126\n",
      "train loss: 0.2229, accuracy: 0.9433\n",
      "test loss: 0.2427, accuracy: 0.9033\n",
      "epoch: 127\n",
      "train loss: 0.2264, accuracy: 0.9167\n",
      "test loss: 0.2433, accuracy: 0.9000\n",
      "epoch: 128\n",
      "train loss: 0.2152, accuracy: 0.9333\n",
      "test loss: 0.2373, accuracy: 0.9133\n",
      "epoch: 129\n",
      "train loss: 0.2176, accuracy: 0.9367\n",
      "test loss: 0.2402, accuracy: 0.8967\n",
      "epoch: 130\n",
      "train loss: 0.2149, accuracy: 0.9200\n",
      "test loss: 0.2332, accuracy: 0.9033\n",
      "epoch: 131\n",
      "train loss: 0.2136, accuracy: 0.9333\n",
      "test loss: 0.2377, accuracy: 0.8933\n",
      "epoch: 132\n",
      "train loss: 0.2143, accuracy: 0.9200\n",
      "test loss: 0.2304, accuracy: 0.9167\n",
      "epoch: 133\n",
      "train loss: 0.2141, accuracy: 0.9267\n",
      "test loss: 0.2449, accuracy: 0.8833\n",
      "epoch: 134\n",
      "train loss: 0.2088, accuracy: 0.9133\n",
      "test loss: 0.2362, accuracy: 0.8900\n",
      "epoch: 135\n",
      "train loss: 0.2046, accuracy: 0.9333\n",
      "test loss: 0.2278, accuracy: 0.9133\n",
      "epoch: 136\n",
      "train loss: 0.2021, accuracy: 0.9333\n",
      "test loss: 0.2275, accuracy: 0.9200\n",
      "epoch: 137\n",
      "train loss: 0.2046, accuracy: 0.9333\n",
      "test loss: 0.2236, accuracy: 0.9167\n",
      "epoch: 138\n",
      "train loss: 0.1991, accuracy: 0.9267\n",
      "test loss: 0.2207, accuracy: 0.9233\n",
      "epoch: 139\n",
      "train loss: 0.1960, accuracy: 0.9433\n",
      "test loss: 0.2216, accuracy: 0.9267\n",
      "epoch: 140\n",
      "train loss: 0.1981, accuracy: 0.9333\n",
      "test loss: 0.2178, accuracy: 0.9233\n",
      "epoch: 141\n",
      "train loss: 0.1945, accuracy: 0.9367\n",
      "test loss: 0.2194, accuracy: 0.9200\n",
      "epoch: 142\n",
      "train loss: 0.1969, accuracy: 0.9233\n",
      "test loss: 0.2158, accuracy: 0.9233\n",
      "epoch: 143\n",
      "train loss: 0.1942, accuracy: 0.9333\n",
      "test loss: 0.2127, accuracy: 0.9167\n",
      "epoch: 144\n",
      "train loss: 0.1886, accuracy: 0.9433\n",
      "test loss: 0.2288, accuracy: 0.8933\n",
      "epoch: 145\n",
      "train loss: 0.1966, accuracy: 0.9133\n",
      "test loss: 0.2103, accuracy: 0.9167\n",
      "epoch: 146\n",
      "train loss: 0.1899, accuracy: 0.9300\n",
      "test loss: 0.2124, accuracy: 0.9100\n",
      "epoch: 147\n",
      "train loss: 0.1890, accuracy: 0.9400\n",
      "test loss: 0.2104, accuracy: 0.9200\n",
      "epoch: 148\n",
      "train loss: 0.1865, accuracy: 0.9333\n",
      "test loss: 0.2080, accuracy: 0.9267\n",
      "epoch: 149\n",
      "train loss: 0.1825, accuracy: 0.9367\n",
      "test loss: 0.2285, accuracy: 0.8967\n",
      "epoch: 150\n",
      "train loss: 0.1890, accuracy: 0.9233\n",
      "test loss: 0.2152, accuracy: 0.9067\n",
      "epoch: 151\n",
      "train loss: 0.1828, accuracy: 0.9400\n",
      "test loss: 0.2042, accuracy: 0.9300\n",
      "epoch: 152\n",
      "train loss: 0.1807, accuracy: 0.9467\n",
      "test loss: 0.2136, accuracy: 0.9067\n",
      "epoch: 153\n",
      "train loss: 0.1795, accuracy: 0.9333\n",
      "test loss: 0.2076, accuracy: 0.9033\n",
      "epoch: 154\n",
      "train loss: 0.1797, accuracy: 0.9300\n",
      "test loss: 0.2052, accuracy: 0.9200\n",
      "epoch: 155\n",
      "train loss: 0.1816, accuracy: 0.9400\n",
      "test loss: 0.2015, accuracy: 0.9233\n",
      "epoch: 156\n",
      "train loss: 0.1791, accuracy: 0.9300\n",
      "test loss: 0.2012, accuracy: 0.9333\n",
      "epoch: 157\n",
      "train loss: 0.1791, accuracy: 0.9367\n",
      "test loss: 0.1978, accuracy: 0.9267\n",
      "epoch: 158\n",
      "train loss: 0.1751, accuracy: 0.9400\n",
      "test loss: 0.2046, accuracy: 0.9033\n",
      "epoch: 159\n",
      "train loss: 0.1719, accuracy: 0.9433\n",
      "test loss: 0.2039, accuracy: 0.9067\n",
      "epoch: 160\n",
      "train loss: 0.1730, accuracy: 0.9433\n",
      "test loss: 0.1963, accuracy: 0.9300\n",
      "epoch: 161\n",
      "train loss: 0.1690, accuracy: 0.9467\n",
      "test loss: 0.1973, accuracy: 0.9267\n",
      "epoch: 162\n",
      "train loss: 0.1676, accuracy: 0.9567\n",
      "test loss: 0.1951, accuracy: 0.9400\n",
      "epoch: 163\n",
      "train loss: 0.1734, accuracy: 0.9433\n",
      "test loss: 0.1941, accuracy: 0.9300\n",
      "epoch: 164\n",
      "train loss: 0.1725, accuracy: 0.9233\n",
      "test loss: 0.1922, accuracy: 0.9367\n",
      "epoch: 165\n",
      "train loss: 0.1665, accuracy: 0.9433\n",
      "test loss: 0.1951, accuracy: 0.9233\n",
      "epoch: 166\n",
      "train loss: 0.1698, accuracy: 0.9433\n",
      "test loss: 0.1907, accuracy: 0.9333\n",
      "epoch: 167\n",
      "train loss: 0.1737, accuracy: 0.9300\n",
      "test loss: 0.1923, accuracy: 0.9300\n",
      "epoch: 168\n",
      "train loss: 0.1661, accuracy: 0.9367\n",
      "test loss: 0.1944, accuracy: 0.9300\n",
      "epoch: 169\n",
      "train loss: 0.1635, accuracy: 0.9567\n",
      "test loss: 0.1894, accuracy: 0.9233\n",
      "epoch: 170\n",
      "train loss: 0.1688, accuracy: 0.9400\n",
      "test loss: 0.1878, accuracy: 0.9300\n",
      "epoch: 171\n",
      "train loss: 0.1675, accuracy: 0.9300\n",
      "test loss: 0.1899, accuracy: 0.9367\n",
      "epoch: 172\n",
      "train loss: 0.1602, accuracy: 0.9500\n",
      "test loss: 0.1859, accuracy: 0.9400\n",
      "epoch: 173\n",
      "train loss: 0.1644, accuracy: 0.9433\n",
      "test loss: 0.1901, accuracy: 0.9267\n",
      "epoch: 174\n",
      "train loss: 0.1597, accuracy: 0.9500\n",
      "test loss: 0.1878, accuracy: 0.9267\n",
      "epoch: 175\n",
      "train loss: 0.1599, accuracy: 0.9400\n",
      "test loss: 0.1840, accuracy: 0.9367\n",
      "epoch: 176\n",
      "train loss: 0.1612, accuracy: 0.9533\n",
      "test loss: 0.1909, accuracy: 0.9200\n",
      "epoch: 177\n",
      "train loss: 0.1582, accuracy: 0.9500\n",
      "test loss: 0.1829, accuracy: 0.9433\n",
      "epoch: 178\n",
      "train loss: 0.1599, accuracy: 0.9433\n",
      "test loss: 0.1847, accuracy: 0.9333\n",
      "epoch: 179\n",
      "train loss: 0.1541, accuracy: 0.9400\n",
      "test loss: 0.1892, accuracy: 0.9267\n",
      "epoch: 180\n",
      "train loss: 0.1539, accuracy: 0.9500\n",
      "test loss: 0.1814, accuracy: 0.9367\n",
      "epoch: 181\n",
      "train loss: 0.1572, accuracy: 0.9400\n",
      "test loss: 0.1960, accuracy: 0.9333\n",
      "epoch: 182\n",
      "train loss: 0.1612, accuracy: 0.9400\n",
      "test loss: 0.1824, accuracy: 0.9367\n",
      "epoch: 183\n",
      "train loss: 0.1533, accuracy: 0.9533\n",
      "test loss: 0.1836, accuracy: 0.9233\n",
      "epoch: 184\n",
      "train loss: 0.1526, accuracy: 0.9533\n",
      "test loss: 0.1787, accuracy: 0.9433\n",
      "epoch: 185\n",
      "train loss: 0.1530, accuracy: 0.9533\n",
      "test loss: 0.1892, accuracy: 0.9100\n",
      "epoch: 186\n",
      "train loss: 0.1558, accuracy: 0.9433\n",
      "test loss: 0.1840, accuracy: 0.9267\n",
      "epoch: 187\n",
      "train loss: 0.1559, accuracy: 0.9400\n",
      "test loss: 0.1775, accuracy: 0.9367\n",
      "epoch: 188\n",
      "train loss: 0.1513, accuracy: 0.9500\n",
      "test loss: 0.1775, accuracy: 0.9367\n",
      "epoch: 189\n",
      "train loss: 0.1491, accuracy: 0.9533\n",
      "test loss: 0.1850, accuracy: 0.9267\n",
      "epoch: 190\n",
      "train loss: 0.1488, accuracy: 0.9500\n",
      "test loss: 0.1790, accuracy: 0.9333\n",
      "epoch: 191\n",
      "train loss: 0.1499, accuracy: 0.9467\n",
      "test loss: 0.1755, accuracy: 0.9400\n",
      "epoch: 192\n",
      "train loss: 0.1469, accuracy: 0.9433\n",
      "test loss: 0.1788, accuracy: 0.9267\n",
      "epoch: 193\n",
      "train loss: 0.1528, accuracy: 0.9433\n",
      "test loss: 0.1769, accuracy: 0.9367\n",
      "epoch: 194\n",
      "train loss: 0.1482, accuracy: 0.9433\n",
      "test loss: 0.1737, accuracy: 0.9467\n",
      "epoch: 195\n",
      "train loss: 0.1425, accuracy: 0.9533\n",
      "test loss: 0.1770, accuracy: 0.9333\n",
      "epoch: 196\n",
      "train loss: 0.1493, accuracy: 0.9433\n",
      "test loss: 0.1757, accuracy: 0.9300\n",
      "epoch: 197\n",
      "train loss: 0.1436, accuracy: 0.9467\n",
      "test loss: 0.1752, accuracy: 0.9300\n",
      "epoch: 198\n",
      "train loss: 0.1449, accuracy: 0.9433\n",
      "test loss: 0.1721, accuracy: 0.9433\n",
      "epoch: 199\n",
      "train loss: 0.1456, accuracy: 0.9467\n",
      "test loss: 0.1734, accuracy: 0.9300\n",
      "epoch: 200\n",
      "train loss: 0.1447, accuracy: 0.9500\n",
      "test loss: 0.1710, accuracy: 0.9433\n",
      "epoch: 201\n",
      "train loss: 0.1426, accuracy: 0.9500\n",
      "test loss: 0.1707, accuracy: 0.9433\n",
      "epoch: 202\n",
      "train loss: 0.1406, accuracy: 0.9600\n",
      "test loss: 0.1733, accuracy: 0.9400\n",
      "epoch: 203\n",
      "train loss: 0.1388, accuracy: 0.9667\n",
      "test loss: 0.1760, accuracy: 0.9333\n",
      "epoch: 204\n",
      "train loss: 0.1427, accuracy: 0.9433\n",
      "test loss: 0.1696, accuracy: 0.9467\n",
      "epoch: 205\n",
      "train loss: 0.1403, accuracy: 0.9567\n",
      "test loss: 0.1754, accuracy: 0.9433\n",
      "epoch: 206\n",
      "train loss: 0.1436, accuracy: 0.9400\n",
      "test loss: 0.1698, accuracy: 0.9433\n",
      "epoch: 207\n",
      "train loss: 0.1410, accuracy: 0.9567\n",
      "test loss: 0.1723, accuracy: 0.9333\n",
      "epoch: 208\n",
      "train loss: 0.1418, accuracy: 0.9567\n",
      "test loss: 0.1685, accuracy: 0.9400\n",
      "epoch: 209\n",
      "train loss: 0.1408, accuracy: 0.9467\n",
      "test loss: 0.1695, accuracy: 0.9367\n",
      "epoch: 210\n",
      "train loss: 0.1382, accuracy: 0.9533\n",
      "test loss: 0.1676, accuracy: 0.9467\n",
      "epoch: 211\n",
      "train loss: 0.1359, accuracy: 0.9633\n",
      "test loss: 0.1815, accuracy: 0.9367\n",
      "epoch: 212\n",
      "train loss: 0.1377, accuracy: 0.9600\n",
      "test loss: 0.1677, accuracy: 0.9433\n",
      "epoch: 213\n",
      "train loss: 0.1350, accuracy: 0.9467\n",
      "test loss: 0.1669, accuracy: 0.9467\n",
      "epoch: 214\n",
      "train loss: 0.1340, accuracy: 0.9600\n",
      "test loss: 0.1727, accuracy: 0.9367\n",
      "epoch: 215\n",
      "train loss: 0.1425, accuracy: 0.9567\n",
      "test loss: 0.1654, accuracy: 0.9467\n",
      "epoch: 216\n",
      "train loss: 0.1404, accuracy: 0.9533\n",
      "test loss: 0.1685, accuracy: 0.9333\n",
      "epoch: 217\n",
      "train loss: 0.1349, accuracy: 0.9567\n",
      "test loss: 0.1688, accuracy: 0.9367\n",
      "epoch: 218\n",
      "train loss: 0.1410, accuracy: 0.9533\n",
      "test loss: 0.1678, accuracy: 0.9300\n",
      "epoch: 219\n",
      "train loss: 0.1342, accuracy: 0.9533\n",
      "test loss: 0.1663, accuracy: 0.9400\n",
      "epoch: 220\n",
      "train loss: 0.1361, accuracy: 0.9500\n",
      "test loss: 0.1649, accuracy: 0.9433\n",
      "epoch: 221\n",
      "train loss: 0.1361, accuracy: 0.9500\n",
      "test loss: 0.1632, accuracy: 0.9533\n",
      "epoch: 222\n",
      "train loss: 0.1318, accuracy: 0.9633\n",
      "test loss: 0.1661, accuracy: 0.9433\n",
      "epoch: 223\n",
      "train loss: 0.1345, accuracy: 0.9567\n",
      "test loss: 0.1629, accuracy: 0.9467\n",
      "epoch: 224\n",
      "train loss: 0.1319, accuracy: 0.9600\n",
      "test loss: 0.1629, accuracy: 0.9533\n",
      "epoch: 225\n",
      "train loss: 0.1334, accuracy: 0.9533\n",
      "test loss: 0.1620, accuracy: 0.9500\n",
      "epoch: 226\n",
      "train loss: 0.1339, accuracy: 0.9633\n",
      "test loss: 0.1675, accuracy: 0.9367\n",
      "epoch: 227\n",
      "train loss: 0.1364, accuracy: 0.9467\n",
      "test loss: 0.1613, accuracy: 0.9467\n",
      "epoch: 228\n",
      "train loss: 0.1319, accuracy: 0.9533\n",
      "test loss: 0.1616, accuracy: 0.9467\n",
      "epoch: 229\n",
      "train loss: 0.1301, accuracy: 0.9600\n",
      "test loss: 0.1640, accuracy: 0.9300\n",
      "epoch: 230\n",
      "train loss: 0.1298, accuracy: 0.9467\n",
      "test loss: 0.1656, accuracy: 0.9333\n",
      "epoch: 231\n",
      "train loss: 0.1289, accuracy: 0.9567\n",
      "test loss: 0.1633, accuracy: 0.9500\n",
      "epoch: 232\n",
      "train loss: 0.1276, accuracy: 0.9600\n",
      "test loss: 0.1632, accuracy: 0.9433\n",
      "epoch: 233\n",
      "train loss: 0.1269, accuracy: 0.9567\n",
      "test loss: 0.1675, accuracy: 0.9333\n",
      "epoch: 234\n",
      "train loss: 0.1311, accuracy: 0.9600\n",
      "test loss: 0.1630, accuracy: 0.9433\n",
      "epoch: 235\n",
      "train loss: 0.1335, accuracy: 0.9500\n",
      "test loss: 0.1602, accuracy: 0.9467\n",
      "epoch: 236\n",
      "train loss: 0.1275, accuracy: 0.9633\n",
      "test loss: 0.1596, accuracy: 0.9500\n",
      "epoch: 237\n",
      "train loss: 0.1227, accuracy: 0.9633\n",
      "test loss: 0.1619, accuracy: 0.9467\n",
      "epoch: 238\n",
      "train loss: 0.1275, accuracy: 0.9600\n",
      "test loss: 0.1588, accuracy: 0.9433\n",
      "epoch: 239\n",
      "train loss: 0.1270, accuracy: 0.9533\n",
      "test loss: 0.1657, accuracy: 0.9367\n",
      "epoch: 240\n",
      "train loss: 0.1251, accuracy: 0.9500\n",
      "test loss: 0.1583, accuracy: 0.9433\n",
      "epoch: 241\n",
      "train loss: 0.1273, accuracy: 0.9533\n",
      "test loss: 0.1589, accuracy: 0.9500\n",
      "epoch: 242\n",
      "train loss: 0.1268, accuracy: 0.9567\n",
      "test loss: 0.1584, accuracy: 0.9500\n",
      "epoch: 243\n",
      "train loss: 0.1242, accuracy: 0.9633\n",
      "test loss: 0.1580, accuracy: 0.9433\n",
      "epoch: 244\n",
      "train loss: 0.1232, accuracy: 0.9633\n",
      "test loss: 0.1642, accuracy: 0.9433\n",
      "epoch: 245\n",
      "train loss: 0.1247, accuracy: 0.9600\n",
      "test loss: 0.1562, accuracy: 0.9500\n",
      "epoch: 246\n",
      "train loss: 0.1273, accuracy: 0.9567\n",
      "test loss: 0.1555, accuracy: 0.9500\n",
      "epoch: 247\n",
      "train loss: 0.1305, accuracy: 0.9500\n",
      "test loss: 0.1552, accuracy: 0.9533\n",
      "epoch: 248\n",
      "train loss: 0.1274, accuracy: 0.9500\n",
      "test loss: 0.1579, accuracy: 0.9467\n",
      "epoch: 249\n",
      "train loss: 0.1282, accuracy: 0.9500\n",
      "test loss: 0.1589, accuracy: 0.9500\n",
      "epoch: 250\n",
      "train loss: 0.1286, accuracy: 0.9600\n",
      "test loss: 0.1548, accuracy: 0.9533\n",
      "epoch: 251\n",
      "train loss: 0.1251, accuracy: 0.9667\n",
      "test loss: 0.1566, accuracy: 0.9400\n",
      "epoch: 252\n",
      "train loss: 0.1213, accuracy: 0.9533\n",
      "test loss: 0.1615, accuracy: 0.9167\n",
      "epoch: 253\n",
      "train loss: 0.1232, accuracy: 0.9633\n",
      "test loss: 0.1588, accuracy: 0.9433\n",
      "epoch: 254\n",
      "train loss: 0.1238, accuracy: 0.9567\n",
      "test loss: 0.1564, accuracy: 0.9400\n",
      "epoch: 255\n",
      "train loss: 0.1212, accuracy: 0.9633\n",
      "test loss: 0.1571, accuracy: 0.9533\n",
      "epoch: 256\n",
      "train loss: 0.1261, accuracy: 0.9600\n",
      "test loss: 0.1546, accuracy: 0.9433\n",
      "epoch: 257\n",
      "train loss: 0.1238, accuracy: 0.9600\n",
      "test loss: 0.1575, accuracy: 0.9533\n",
      "epoch: 258\n",
      "train loss: 0.1224, accuracy: 0.9633\n",
      "test loss: 0.1583, accuracy: 0.9333\n",
      "epoch: 259\n",
      "train loss: 0.1239, accuracy: 0.9533\n",
      "test loss: 0.1534, accuracy: 0.9467\n",
      "epoch: 260\n",
      "train loss: 0.1288, accuracy: 0.9567\n",
      "test loss: 0.1522, accuracy: 0.9500\n",
      "epoch: 261\n",
      "train loss: 0.1245, accuracy: 0.9567\n",
      "test loss: 0.1530, accuracy: 0.9500\n",
      "epoch: 262\n",
      "train loss: 0.1225, accuracy: 0.9600\n",
      "test loss: 0.1549, accuracy: 0.9433\n",
      "epoch: 263\n",
      "train loss: 0.1193, accuracy: 0.9533\n",
      "test loss: 0.1523, accuracy: 0.9533\n",
      "epoch: 264\n",
      "train loss: 0.1177, accuracy: 0.9633\n",
      "test loss: 0.1553, accuracy: 0.9433\n",
      "epoch: 265\n",
      "train loss: 0.1140, accuracy: 0.9633\n",
      "test loss: 0.1566, accuracy: 0.9500\n",
      "epoch: 266\n",
      "train loss: 0.1210, accuracy: 0.9500\n",
      "test loss: 0.1507, accuracy: 0.9533\n",
      "epoch: 267\n",
      "train loss: 0.1224, accuracy: 0.9567\n",
      "test loss: 0.1511, accuracy: 0.9500\n",
      "epoch: 268\n",
      "train loss: 0.1234, accuracy: 0.9500\n",
      "test loss: 0.1504, accuracy: 0.9533\n",
      "epoch: 269\n",
      "train loss: 0.1163, accuracy: 0.9567\n",
      "test loss: 0.1511, accuracy: 0.9500\n",
      "epoch: 270\n",
      "train loss: 0.1191, accuracy: 0.9567\n",
      "test loss: 0.1507, accuracy: 0.9533\n",
      "epoch: 271\n",
      "train loss: 0.1187, accuracy: 0.9567\n",
      "test loss: 0.1543, accuracy: 0.9367\n",
      "epoch: 272\n",
      "train loss: 0.1182, accuracy: 0.9633\n",
      "test loss: 0.1567, accuracy: 0.9267\n",
      "epoch: 273\n",
      "train loss: 0.1137, accuracy: 0.9567\n",
      "test loss: 0.1490, accuracy: 0.9533\n",
      "epoch: 274\n",
      "train loss: 0.1205, accuracy: 0.9467\n",
      "test loss: 0.1541, accuracy: 0.9400\n",
      "epoch: 275\n",
      "train loss: 0.1159, accuracy: 0.9633\n",
      "test loss: 0.1508, accuracy: 0.9467\n",
      "epoch: 276\n",
      "train loss: 0.1151, accuracy: 0.9633\n",
      "test loss: 0.1518, accuracy: 0.9533\n",
      "epoch: 277\n",
      "train loss: 0.1166, accuracy: 0.9633\n",
      "test loss: 0.1578, accuracy: 0.9233\n",
      "epoch: 278\n",
      "train loss: 0.1172, accuracy: 0.9667\n",
      "test loss: 0.1548, accuracy: 0.9400\n",
      "epoch: 279\n",
      "train loss: 0.1134, accuracy: 0.9633\n",
      "test loss: 0.1499, accuracy: 0.9533\n",
      "epoch: 280\n",
      "train loss: 0.1162, accuracy: 0.9533\n",
      "test loss: 0.1506, accuracy: 0.9500\n",
      "epoch: 281\n",
      "train loss: 0.1189, accuracy: 0.9700\n",
      "test loss: 0.1478, accuracy: 0.9567\n",
      "epoch: 282\n",
      "train loss: 0.1188, accuracy: 0.9600\n",
      "test loss: 0.1484, accuracy: 0.9533\n",
      "epoch: 283\n",
      "train loss: 0.1142, accuracy: 0.9667\n",
      "test loss: 0.1524, accuracy: 0.9433\n",
      "epoch: 284\n",
      "train loss: 0.1123, accuracy: 0.9700\n",
      "test loss: 0.1500, accuracy: 0.9433\n",
      "epoch: 285\n",
      "train loss: 0.1192, accuracy: 0.9600\n",
      "test loss: 0.1508, accuracy: 0.9467\n",
      "epoch: 286\n",
      "train loss: 0.1114, accuracy: 0.9600\n",
      "test loss: 0.1471, accuracy: 0.9533\n",
      "epoch: 287\n",
      "train loss: 0.1109, accuracy: 0.9633\n",
      "test loss: 0.1481, accuracy: 0.9567\n",
      "epoch: 288\n",
      "train loss: 0.1143, accuracy: 0.9533\n",
      "test loss: 0.1534, accuracy: 0.9467\n",
      "epoch: 289\n",
      "train loss: 0.1126, accuracy: 0.9600\n",
      "test loss: 0.1486, accuracy: 0.9500\n",
      "epoch: 290\n",
      "train loss: 0.1125, accuracy: 0.9733\n",
      "test loss: 0.1485, accuracy: 0.9533\n",
      "epoch: 291\n",
      "train loss: 0.1136, accuracy: 0.9700\n",
      "test loss: 0.1472, accuracy: 0.9500\n",
      "epoch: 292\n",
      "train loss: 0.1130, accuracy: 0.9600\n",
      "test loss: 0.1495, accuracy: 0.9433\n",
      "epoch: 293\n",
      "train loss: 0.1118, accuracy: 0.9700\n",
      "test loss: 0.1456, accuracy: 0.9533\n",
      "epoch: 294\n",
      "train loss: 0.1111, accuracy: 0.9600\n",
      "test loss: 0.1591, accuracy: 0.9367\n",
      "epoch: 295\n",
      "train loss: 0.1170, accuracy: 0.9533\n",
      "test loss: 0.1451, accuracy: 0.9533\n",
      "epoch: 296\n",
      "train loss: 0.1115, accuracy: 0.9567\n",
      "test loss: 0.1459, accuracy: 0.9567\n",
      "epoch: 297\n",
      "train loss: 0.1096, accuracy: 0.9667\n",
      "test loss: 0.1464, accuracy: 0.9533\n",
      "epoch: 298\n",
      "train loss: 0.1128, accuracy: 0.9500\n",
      "test loss: 0.1476, accuracy: 0.9533\n",
      "epoch: 299\n",
      "train loss: 0.1090, accuracy: 0.9633\n",
      "test loss: 0.1471, accuracy: 0.9467\n",
      "epoch: 300\n",
      "train loss: 0.1082, accuracy: 0.9667\n",
      "test loss: 0.1458, accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import dezero\n",
    "import dezero.functions as F\n",
    "from dezero.models import MLP\n",
    "from dezero import optimizers\n",
    "\n",
    "max_epoch = 300\n",
    "batch_size = 30\n",
    "hidden_size = 10\n",
    "lr = 1.0\n",
    "\n",
    "train_set = dezero.datasets.Spiral(train=True)\n",
    "test_set = dezero.datasets.Spiral(train=False)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size, shuffle=False)\n",
    "\n",
    "model = MLP((hidden_size, 3))\n",
    "optimizer = optimizers.SGD(lr).setup(model)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        acc = F.accuracy(y, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "        sum_acc += float(acc.data) * len(t)\n",
    "\n",
    "    print('epoch: {}'.format(epoch+1))\n",
    "    print('train loss: {:.4f}, accuracy: {:.4f}'.format(\n",
    "        sum_loss / len(train_set), sum_acc / len(train_set)))\n",
    "\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    \n",
    "    with dezero.no_grad():\n",
    "        for x, t in test_loader:\n",
    "            y = model(x)\n",
    "            loss = F.softmax_cross_entropy(y, t)\n",
    "            acc = F.accuracy(y, t)\n",
    "            sum_loss += float(loss.data) * len(t)\n",
    "            sum_acc += float(acc.data) * len(t)\n",
    "\n",
    "    print('test loss: {:.4f}, accuracy: {:.4f}'.format(\n",
    "        sum_loss / len(test_set), sum_acc / len(test_set)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
